# AST21119 Ethics in Technology  
## Lecture 1 - An Overview of Ethics  

---

## Difference Between Morals, Ethics, and Laws  

- **Morals (道德)**: Personal beliefs about right and wrong.  
- **Ethics (倫理)**: Standards or codes of behavior expected by a group (nation, society, organization, profession).  
- **Law (法律)**: System of rules enforced by institutions (e.g., courts, police).  
  - *Legal acts* conform to the law.  
  - *Moral acts* align with personal beliefs.  

---

## Four Common Approaches to Ethical Decision Making  

| Approach               | Principle                                                                 |
|------------------------|---------------------------------------------------------------------------|
| **Virtue Ethics**      | Choice reflects moral virtues (e.g., honesty, courage) in oneself/community. |
| **Utilitarian**        | Choice maximizes benefits over harms for all affected parties.            |
| **Fairness**           | Choice treats everyone equally, avoiding favoritism/discrimination.       |
| **Common Good**        | Choice advances collective well-being (e.g., peace, justice, education).  |

---

### **Virtue Ethics Approach**  
- **Principles**:  
  - Focus on ideals like honesty, compassion, integrity.  
  - Virtues guide "right" decisions.  
- **Problems**:  
  - No clear action guide; context-dependent.  

### **Utilitarian Approach**  
- **Principles**:  
  - Optimize overall consequences (greatest good for greatest number).  
  - Uses cost-benefit analysis.  
- **Problems**:  
  - Difficult to measure/compare values; hard to predict outcomes.  

### **Fairness Approach**  
- **Principles**:  
  - Equal treatment unless relevant differences exist (e.g., contribution).  
- **Problems**:  
  - Subjective bias; perceived unfairness (e.g., CEO pay gaps).  

### **Common Good Approach**  
- **Principles**:  
  - Promotes shared goals (e.g., clean environment, public health).  
- **Problems**:  
  - Consensus challenges; "free-rider" issues.  

---

## Other Ethical Approaches  
- **Duty/Rights Approach** (Kant, Locke):  
  - Emphasizes rationality, human dignity, and universal rights.  

---

## Corporate Ethics Programme  
**Key Components**:  
1. **Code of Ethics**: Guides behavior, identifies risks, ensures compliance.  
2. **Ethics Officer**: Senior leader fostering ethical culture.  
3. **Social Audits**: Review ethical/social responsibility goals.  
4. **Ethics Training**: Encourages reporting misconduct without retaliation.  
5. **Ethical Appraisals**: Evaluates fairness, accountability, honesty.  

**Case Study**:  
- **Securities and Futures Commission (SFC)**: Regulates HK listed companies via CAP 571 (market rules, licensing, investor education).  

---

## Ethical Decision-Making Process  
1. **Problem Statement**: Clear, specific description (e.g., "15% out-of-stock rate costs $300K/month").  
2. **Alternatives**: Brainstorm with stakeholders; weigh laws/ethics.  
3. **Implementation**: Choose defensible, policy-aligned solutions.  
4. **Evaluation**: Assess outcomes and unintended consequences.  

**Manager’s Checklist**:  
- Code of ethics awareness.  
- Safe reporting mechanisms.  
- Leadership modeling ethical behavior.  

---

> *"Good employees sometimes make bad ethical choices when pressured."*  
> **Solution**: Provide anonymous reporting channels (e.g., internal website).

# AST21119 Ethics in Technology  
## Lecture 2 - Ethics for IT / Engineering  

---

## **IT Professionals**  
- **Requirements**:  
  - Specialized knowledge & intensive academic preparation.  
  - Advanced training, discretion, non-standardized work.  
  - **Responsibilities**: Contribute to society, lifelong training, uphold rights.  

### **Are We IT Professionals?**  
| **Engineers**               | **IT/SCI Workers**               |  
|-----------------------------|----------------------------------|  
| - Legal definition (Cap 409). | - No legal licensing.           |  
| - Chartered titles (CEng).   | - Certifications (e.g., security).|  
| - HKIE/IEEE memberships.     | - HKCS/ACM memberships.          |  

---

## **Changing Professional Services Industry**  
**Seven Forces**:  
1. Client sophistication  
2. Governance (*治理*)  
3. Connectivity  
4. Transparency  
5. Modularization (*模組化*)  
6. Globalization  
7. Commoditization (*商优化*)  

---

## **Relationships & Ethical Challenges**  

### **IT Workers vs. Employers**  
- **Software piracy**: Illegal copying/access.  
- **Trade secrets**: Confidential, costly-to-develop info.  
- **Whistle-blowing**: Exposing illegal/immoral acts.  

### **IT Workers vs. Clients**  
- **Trust**: Accurate assessments, full reporting.  
- **Ethical issues**:  
  - Conflict of interest (self-recommendations).  
  - **Fraud** (*欺詐*), **Misrepresentation** (*歪曲*), **Breach of contract** (*違反合約*).  

### **IT Workers vs. Suppliers**  
- **Bribery** (*贿赂*): Illegal advantages (POBO, ICAC).  
- **Gifts vs. Bribes**:  
  | **Bribes**               | **Gifts**                |  
  |--------------------------|--------------------------|  
  | Secret, creates obligation | Public, no expectations |  

### **IT Workers vs. Users**  
- **Duties**: Understand needs, discourage piracy, protect data.  
- **User policies**: Define acceptable IT resource use.  

---

## **Professional Codes of Ethics**  
- **Purpose**: Guide ethical behavior, set standards.  
- **Benefits**: Trust, self-assessment, high standards.  
- **Key Organizations**:  
  - HKIE, IEEE, ACM, HKCS, AITP, SANS.  

---

## **Certification & Compliance**  
- **Certification**: Validates skills (e.g., HKIIT).  
  - *Voluntary, employer-valued but debated*.  
- **Compliance**:  
  - **Tools**: Tracking software, Chief Compliance Officer.  
  - **Audit Committee**: Oversees accounting, legal adherence.  

---

## **Common Ethical Issues for IT Users**  
1. **Software piracy**.  
2. **Inappropriate resource use** (e.g., productivity loss).  
3. **Data misuse** (private/confidential info).  

**Policy Solutions**:  
- Define user rights/responsibilities.  
- Install firewalls, structure data protection.  

---

> *"Negligence (*疏忽*) breaches duty of care (*謹慎責任*), leading to malpractice (*專業失德*) liabilities."*
>


# AST21119 Ethics in Technology  
## Lecture 3 - Computer and Internet Crime  

---

## **IT Security Incidents: A Major Concern**  
- **Objectives**:  
  - Safeguard confidential business data and private customer/employee information.  
  - Protect against theft and operational disruptions.  
- **Examples**:  
  - **Ransomware (WannaCry)**: Encrypts files, demands Bitcoin payment.  
  - **Data Breaches**: Hacking of customer databases (e.g., Hong Kong travel agency).  
- **Trends**:  
  - Cybercrime costs projected to rise globally (e.g., \$1.16T in 2019 → \$trillions by 2028).  

---

## **Ethical Dilemma in Security Incidents**  
**Organizations face tough choices**:  
- Prosecute criminals aggressively?  
- Avoid negative publicity by staying silent?  
- Notify affected customers proactively?  

---

## **Why Computer Incidents Are Prevalent**  
1. **Complexity**: Cloud, AI, and IoT increase vulnerabilities.  
2. **User Expectations**: Pressure for rapid software development.  
3. **Poor Practices**: Shared passwords, unsecured Wi-Fi.  
4. **Outdated Defenses**: Slow adaptation to new threats.  

---

## **Types of Exploits**  
| **Attack**               | **Description**                                  |  
|--------------------------|------------------------------------------------|  
| **Virus**                | Malware attached to files; spreads via email/downloads. |  
| **Worm**                 | Self-replicating; consumes resources (e.g., bandwidth). |  
| **Trojan Horse**         | Disguised malware (e.g., hidden in "free" software). |  
| **DDoS**                 | Overwhelms targets with botnet traffic.         |  
| **Phishing**             | Fraudulent emails/sites to steal data (e.g., spear-phishing). |  

---

## **Perpetrators of Cybercrime**  
| **Type**            | **Motive**                                  |  
|---------------------|--------------------------------------------|  
| **Hackers**         | Challenge/publicity (may be malicious).     |  
| **Crackers**        | Profit or system corruption.                |  
| **Malicious Insiders** | Financial gain or sabotage (hard to detect). |  
| **Cyberterrorists** | Political/social disruption.                |  

---

## **Laws in Hong Kong**  
- **Telecommunications Ordinance (Cap. 106)**: Unauthorized access via telecoms.  
- **Crimes Ordinance (Cap. 200)**: Computer fraud/data falsification.  
- **Theft Ordinance (Cap. 210)**: Unlawful data alteration/theft.  

---

## **Trustworthy Computing (Microsoft’s Framework)**  
1. **Security**: Collaborate with law enforcement; educate users.  
2. **Privacy**: Design products with data protection in mind.  
3. **Reliability**: Minimize bugs, ensure uptime.  
4. **Business Integrity**: Transparency and accountability.  

---

## **Risk Assessment & Mitigation**  
**8-Step Process**:  
1. Identify critical assets.  
2. List potential threats (e.g., DDoS).  
3. Estimate likelihood/impact.  
4. Prioritize countermeasures (e.g., firewalls, encryption).  

**Example Risk Matrix**:  
| **Threat**               | **Probability** | **Cost**  | **Priority** |  
|--------------------------|----------------|-----------|-------------|  
| DDoS Attack              | 40%            | \$500K    | 1           |  
| Email Worm               | 70%            | \$200K    | 2           |  

---

## **Prevention & Response**  
- **Layered Security**: Firewalls, intrusion prevention, antivirus.  
- **Employee Training**: Password hygiene, reporting anomalies.  
- **Incident Response Plan**:  
  - Contain attacks, preserve evidence, notify stakeholders.  
  - Only 50% of businesses have a formal plan.  

> *"Security depends on **technology**, **policy**, and **people**—monitoring and rapid response are critical."*  


# AST21119 Ethics in Technology  
## Lecture 4 - Freedom of Expression  

---

## **Freedom of Expression: Fundamental Rights**  
- **Definition**:  
  - Right to voice opinions publicly without fear of **censorship** or punishment.  
  - Includes nonverbal, visual, and symbolic forms of expression.  
  - Right to speak anonymously.  

- **Under Hong Kong Basic Law (Chapter III)**:  
  - Freedom of speech, press, and publication.  
  - Freedom of assembly, procession, and demonstration.  
  - Right to form trade unions and strike.  
  - Privacy of communication (except for public security/criminal investigations).  

---

## **Limits to Free Expression**  
**Not protected by law**:  
1. **Obscenity** (淫穢)  
2. **Defamation** (誹謗) – False statements harming reputation.  
   - *Libel* (written) vs. *Slander* (spoken).  
3. **Perjury** (偽證) – Lying under oath.  
4. **Fraud** (欺詐) – Deception for gain.  
5. **Incitement** (教唆) & **Sedition** (煽動叛亂).  
6. **Fighting words** (挑釁言論) – Provoking violence.  

---

## **Controlling Internet Access**  
- **Children’s Protection**:  
  - **USA (CIPA)**: Requires filters in schools/libraries.  
  - **France**: Proposed parental consent for social media (<16).  
- **Filtering Methods**:  
  - **URL/Keyword Blocking**: Bans specific sites/phrases.  
  - **Dynamic Content Filtering**: Evaluates content in real-time.  
  - **ISP Blocking**: Subscriptions to filtered services (e.g., ClearSail).  

- **Internet Censorship**:  
  - Blocks sites, monitors activity, jails users (e.g., political dissent).  

---

## **Anonymity & Ethical Challenges**  
- **Pros**:  
  - Shields whistleblowers/dissidents in oppressive regimes.  
- **Cons**:  
  - **Doxxing** (起底): Malicious exposure of private info.  
  - **Anonymous Remailers**: Enable untraceable (potentially illegal) communication.  

---

## **Hate Speech & Fake News**  
- **Prosecutable Hate Speech**:  
  - Threats, intimidation, or racist/xenophobic content.  
  - **EU Code of Conduct**: Facebook/Twitter remove illegal hate speech within 24hrs.  
- **Fake News**:  
  - Deliberate misinformation via media/social platforms.  
  - *Example*: "Alternative facts" about Trump’s inauguration crowd size.  

---

> *"Free expression is a cornerstone of democracy but must balance with protections against harm."*
>

# AST21119 Ethics in Technology  
## Lecture 5 - Privacy  

---

## **Information Privacy**  
- **Definition**:  
  - **Communications Privacy**: Freedom from monitoring in communications.  
  - **Data Privacy**: Control over personal data collection/use.  

- **Hong Kong's Personal Data (Privacy) Ordinance**:  
  - Applies to all organizations/government controlling personal data.  

---

## **Six Data Protection Principles (DPP)**  
| **Principle**               | **Key Requirement**                                                                 |
|-----------------------------|------------------------------------------------------------------------------------|
| **DPP1: Collection**        | Lawful, fair collection for direct purpose (e.g., age range vs. birthdate).         |
| **DPP2: Accuracy**          | Data must be accurate; retained only as needed.                                     |
| **DPP3: Use**               | Data used only for original purpose unless new consent obtained.                    |
| **DPP4: Security**          | Safeguard against unauthorized access/loss.                                         |
| **DPP5: Openness**          | Public disclosure of data policies.                                                 |
| **DPP6: Access/Correction** | Individuals can access/correct their data.                                          |

---

## **Advanced Surveillance Technologies**  
- **Public Cameras**: Debated over privacy vs. security (e.g., London's HD street cameras).  
- **Facial Recognition**:  
  - Used in airports/stores to identify individuals.  
  - Scans facial patterns against databases.  
- **Satellite Surveillance**:  
  - Over 200 operational satellites (e.g., SpaceX, China BDS-3).  

---

## **Key Privacy Issues**  
### 1. **Identity Theft**  
- **Theft Targets**: Name, ID/passport numbers, address.  
- **Methods**:  
  - Data breaches (hacking/lost laptops).  
  - Phishing, spyware (keystroke logging).  
- **Penalty**: Up to 14 years imprisonment (HK Theft Ordinance).  

### 2. **Consumer Profiling**  
- **Tracking Tools**: Cookies, GPS, credit card data.  
- **Mitigation**:  
  - Browser cookie limits, anonymizing software.  
  - **Chief Privacy Officer (CPO)**: Oversees data policies.  

### 3. **Workplace Monitoring**  
- **Reasons**: Productivity loss, legal risks (e.g., harassment).  
- **HK Case Violation**: Covert cameras breached DPP5 (Openness).  

---

## **Emerging Privacy Debates**  
- **FBI vs. Apple/Amazon**: Law enforcement access to devices/cloud data.  
- **Public Sentiment**: Polls reveal mixed feelings (happy → angry).  

---

> *"Privacy is not an option, and it shouldn’t be the price we accept for just getting on the Internet."*  
> **– Gary Kovacs**  

# AST21119 Ethics in Technology  
## Lecture 6 - Intellectual Property  

---

## **Intellectual Property (IP) Overview**  
- **Definition**: Creations of the mind (art, inventions, processes) with distinct ownership.  
- **Hong Kong Context**:  
  - Protected under Basic Law (research, patents, cultural works).  
  - Critical for international trade and creative industries (film, design).  

### **Types of IP Protection**  
| **Type**               | **Protects**                                | **Key Feature**                          |  
|------------------------|--------------------------------------------|------------------------------------------|  
| **Copyright**          | Original works (books, software, music)    | Automatic; no registration required.     |  
| **Patent**             | Inventions (useful, novel, non-obvious)    | Requires application (20-year max).      |  
| **Trademark**          | Brand identifiers (logos, sounds, colors)  | Distinguishes goods/services.            |  
| **Trade Secret**       | Confidential business info (recipes, algorithms) | No time limit; enforced via NDAs. |  
| **Registered Design**  | Product appearance                         | Prevents copying of visual design.       |  

---

## **Copyright in Hong Kong**  
- **Scope**: Covers literary, musical, artistic works, films, broadcasts, and software.  
- **Ownership**:  
  - Default: Author (employers own employee-created works unless agreed otherwise).  
  - Duration: Life + 50 years (authors) or 50 years (anonymous/corporate works).  
- **Infringement**: Unauthorized copying/distribution (civil penalties apply).  
- **Fair Use**: Research, education, criticism (with attribution).  

**Controversy**: Derivative works (parody/kuso) under 2011 Amendment Bill debates.  

---

## **Patents & Trademarks**  
### **Patents**  
- **Requirements**: Useful, novel, non-obvious inventions (products/processes).  
- **Registration**:  
  - HK Patents Ordinance (Cap.514); no automatic protection.  
  - Types: Standard (20 years) vs. Short-term (8 years).  
- **Global Note**: Patents are territorial (apply country-by-country).  

### **Trademarks**  
- **Elements**: Words, designs, sounds, smells (must be graphically representable).  
- **Purpose**: Prevent consumer confusion; distinguish brands.  

---

## **Trade Secrets & Reverse Engineering**  
- **Trade Secrets**:  
  - Advantages: No disclosure, indefinite protection.  
  - Risks: Employee leaks; independent discovery allowed.  
- **Reverse Engineering**:  
  - Ethical if for interoperability/bug fixes (e.g., software decompilation).  

---

## **Plagiarism & Open Source**  
### **Plagiarism**  
- **Definition**: Passing off others' work as one’s own (academic/industry issue).  
- **Prevention**: Education, phased assignments, detection tools (Turnitin).  

### **Open Source Software (OSS)**  
- **Principles**: Free use/modification (GPL, LGPL, MIT licenses).  
- **Movement**:  
  - **1985**: Free Software Foundation (copyleft concept).  
  - **1998**: Open Source Initiative (OSI) promotes collaboration.  
- **Examples**: Linux, Android, Apache.  

---

## **Creative Commons & Open Content**  
- **Creative Commons (CC)**:  
  - Licenses combine elements: Attribution (BY), ShareAlike (SA), NonCommercial (NC), NoDerivatives (ND).  
  - Public Domain options (CC0).  
- **Open Content Alliance (OCA)**:  
  - Digitizes works with permission (opt-in) vs. Google Books’ opt-out approach.  

---

> *"IP protection balances innovation incentives with public access—key to ethical technology development."*
>

# AST21119 Ethics in Technology  
## Lecture 7 - Social Networking  

---

## **Social Networking Overview**  
- **Purpose**: Breaks barriers of time/distance, enabling global interaction through shared opinions, experiences, and interests.  
- **Usage**:  
  - **Daily Time Spent (2023)**: 2h 24m on social media (↓2.5% YoY).  
  - **Top Platforms (U.S.)**: YouTube (73%), Facebook (69%), Instagram (37%).  
- **Demographics**:  
  - **Age**: 91% of 18-29-year-olds use YouTube; 46% of 65+ use Facebook.  
  - **Gender**: Women dominate Pinterest (42%) vs. men (15%).  

---

## **Ethical Issues in Social Networking**  

### **1. Fake Identities**  
- **Examples**:  
  - Psychologist posing as a woman in a disability forum.  
  - Fake profiles for buying "likes" or social engineering experiments.  
- **Risks**: Exposure to identity theft and sophisticated crimes.  

### **2. Cyberbullying**  
- **Forms**: Threatening messages, impersonation, doctored photos, online polls.  
- **Impact**:  
  - Higher depression/suicide rates among teens (2× more likely).  
  - **Hong Kong Context**: Schools liable under Disability Discrimination Ordinance (DDO) if they ignore bullying.  

### **3. Cyberstalking**  
- **Methods**: False accusations, monitoring, threats, humiliation.  
- **Goal**: Anger, revenge, or control over the victim.  

### **4. Sexual Predators**  
- **Actions**: Targeting minors for abusive contact.  
- **Countermeasures**:  
  - MySpace banned 90,000 sex offenders (2009).  
  - U.S. mandates sex offender registration.  

### **5. Inappropriate Content**  
- **Challenge**: Limited resources to review all uploads (violence/obscenity).  

---

## **Anti-Social Media Critique**  
- **Criticisms**:  
  - Ex-Facebook executives: "Rips society apart," exploits psychological vulnerabilities.  
  - Role in political manipulation (2016 U.S. election, Brexit, Myanmar Rohingya crisis).  
- **Platform Responses**:  
  - **Facebook**: Downvote feature, "angry/love" reactions, anti-fraud measures.  
  - Focus on combating hate speech and decentralizing tech power.  

---

## **Key Statistics**  
### **Brand Interactions (2023)**  
| **Action**                          | **16-24yo** | **55-64yo** |  
|-------------------------------------|------------|------------|  
| Visited brand website               | 43.3%      | 45.2%      |  
| Watched brand video                 | 25.0%      | 21.2%      |  
| Followed brand on social media      | 23.8%      | 16.8%      |  

### **Bullying Types (2019)**  
- **Cyberbullying**: Higher among females (social/verbal bullying dominant).  

---

> *"Social media connects the world but demands ethical safeguards to protect users from harm."*
>
# AI vs Ethics

## What Are Ethics in AI?
AI ethics refers to a system of **moral principles** guiding the development and use of artificial intelligence. It ensures AI aligns with societal values and mitigates harm. Key aspects include:
- **Purpose**: Provides stakeholders with guidance for ethical decision-making.
- **Scope**: Covers fairness, accountability, transparency, and privacy.

---

## Ethical Challenges of AI

### 1. **Responsibility**
- **Issue**: Determining accountability for AI decisions with catastrophic outcomes (e.g., autonomous vehicle accidents).
- **Solution**: Legal frameworks involving lawyers, regulators, and citizens.

### 2. **Misuse**
- **Issue**: AI algorithms repurposed for harmful activities (e.g., deepfake propaganda).
- **Solution**: Risk analysis during design and safety measures.

### 3. **Explainability**
- **Issue**: Lack of transparency in AI decision-making ("black box" problem).
- **Solution**: Traceable algorithms and clear documentation of data sources.

### 4. **Fairness**
- **Issue**: Biases in datasets leading to discriminatory outcomes (e.g., racial/gender bias in hiring AI).
- **Solution**: Auditing datasets and models for bias.

---

## AI Code of Ethics: Key Areas

| **Area**       | **Focus**                                                                 | Example Measures                                                                 |
|----------------|---------------------------------------------------------------------------|---------------------------------------------------------------------------------|
| **Policy**     | Standardization, legal frameworks, and corporate conduct.                | Integrating AI ethics into company codes of conduct.                            |
| **Education**  | Training stakeholders on ethical risks and responsible AI use.            | Workshops on data privacy and algorithmic bias for employees.                   |
| **Technology** | Detecting unethical AI behavior and ensuring transparency.                | Tools to identify deepfakes or biased datasets; vetting third-party AI systems. |

---

## Examples of Ethical AI Principles
1. **Inclusive AI**:  
   - Unbiased models trained on diverse datasets.  
   - Regular audits to prevent future corruption.  

2. **Explainable AI**:  
   - Prioritizing interpretable algorithms over "black box" models.  

3. **Purpose-Driven AI**:  
   - Designed for societal good (e.g., fraud reduction, climate solutions).  

4. **Data Responsibility**:  
   - Minimal data collection (e.g., zip codes vs. exact locations).  
   - Routine deletion of unnecessary data.  

---

## The Future of Ethical AI
- **Proactive vs. Reactive**: Moving from rigid rules to guiding principles (e.g., defining "fairness" in lending AI).  
- **Human-Centric Design**: Prioritizing equity for marginalized groups and preventing economic divides.  
- **Global Collaboration**: UNESCO and other bodies advocate for international ethical standards.  

> *"Ethical AI isn’t about eliminating bias—it’s about defining fairness and aligning technology with human values."*  

**References**:  
- [UNESCO AI Ethics](https://www.unesco.org/en/artificial-intelligence/recommendation-ethics)  
- [AI4Good Foundation](https://ai4good.org/about-us/)  
